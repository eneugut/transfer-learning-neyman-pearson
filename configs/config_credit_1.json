{
    "exp_description": "Credit deliquency data.",
    "seeds": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],
    "num_source_points_list": [100, 500, 1000, 2000, 3000],
    "credit_config": {
        "target_min_age": 0,
        "target_max_age": 36,
        "source_min_age": 37,
        "source_max_age": 100,
        "num_target_abnormal_training": 60,
        "num_target_abnormal_test": 2000,
        "num_target_normal_training": 4000,
        "num_target_normal_test": 5000,
        "num_source_abnormal": 3000
    },
    "model_config": {
        "model_name": "MultiLayerPerceptron",
        "hidden_dim": 4,
        "input_dim": 9
    },
    "training_config": {
        "device": "cpu",
        "alpha": 0.10,
        "normalize_losses": true,
        "num_epochs": 600,
        "batch_size": 512,
        "lambda_source_list": [0, 0.05, 0.1, 0.5, 1, 5, 10, 20, 40, 60, 80, 100],
        "method1_constant": 1.5,
        "method2_constant": 7.5,
        "lambda_limit": 1e6,
        "data_standardization": true,
        "cols_to_standardize": [0, 2, 3],
        "early_stopping_patience": 30,
        "early_stopping_min_delta": 0.001,
        "max_grad_norm": 3.0,
        "max_tuning_tries": 45,
        "loss_function": "ExponentialLoss"
    },
    "optimizer_config": {
        "optimizer_name": "Adam",
        "learning_rate": 0.002,
        "SGD": {
            "momentum": 0
        },
        "Adam": {
            "betas": [0.9, 0.999]
        },
        "RMSprop": {
            "alpha": 0.99
        }
},
    "scheduler_config": {
        "scheduler_name": "ReduceLROnPlateau",
        "StepLR": {
            "step_size": 10,
            "gamma": 0.5
        },
        "ReduceLROnPlateau": {
            "factor": 0.10, 
            "patience": 5
        },
        "ExponentialLR": {
            "gamma": 0.9
        }
    }
}
