{
    "exp_description": "New codebase. source_mean = 0.8. 60 abnormal.",
    "seeds": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],
    "num_source_points_list": [100, 500, 1000, 2000, 2500, 3000],
    "data_generation_config": {
        "target_normal_class_config": {
            "label": -1,
            "num_training_datapoints": 4000,
            "num_test_datapoints": 5000,
            "num_features": 15,
            "distribution_type": "normal",
            "mean": 0,
            "cov_value": 1,
            "random_covariances": false,
            "cov_distribution_type": "normal"
        },
        "target_abnormal_class_config": {
            "label": 1,
            "num_training_datapoints": 25,
            "num_test_datapoints": 5000,
            "num_features": 15,
            "distribution_type": "normal",
            "mean": 0.5,
            "cov_value": 1,
            "random_covariances": false,
            "cov_distribution_type": "normal"
        },
        "source_abnormal_class_config": {
            "label": 1,
            "num_training_datapoints": 3000,
            "num_test_datapoints": null,
            "num_features": 15,
            "distribution_type": "normal",
            "mean": 0.5,
            "cov_value": 1,
            "random_covariances": false,
            "cov_distribution_type": "normal"
        }
    },
    "model_config": {
        "model_name": "QuadraticForm",
        "input_dim": 15
    },
    "training_config": {
        "device": "cuda",
        "alpha": 0.055,
        "normalize_losses": true,
        "run_method3": true,
        "num_epochs": 600,
        "batch_size": 512,
        "lambda_source_list": [0, 0.05, 0.1, 0.5, 1, 5, 10, 20, 40, 60, 80, 100],
        "method1_constant": 2.5,
        "method2_constant": 7.5,
        "lambda_limit": 1e6,
        "data_standardization": false,
        "early_stopping_patience": 30,
        "early_stopping_min_delta": 0.001,
        "max_grad_norm": 1.0,
        "loss_function": "ExponentialLoss"
    },
    "optimizer_config": {
        "optimizer_name": "Adam",
        "learning_rate": 0.001,
        "SGD": {
            "momentum": 0
        },
        "Adam": {
            "betas": [0.9, 0.999]
        },
        "RMSprop": {
            "alpha": 0.99
        }
    },
    "scheduler_config": {
        "scheduler_name": "ReduceLROnPlateau",
        "StepLR": {
            "step_size": 10,
            "gamma": 0.5
        },
        "ReduceLROnPlateau": {
            "factor": 0.25, 
            "patience": 5
        },
        "ExponentialLR": {
            "gamma": 0.9
        }
    }
}

